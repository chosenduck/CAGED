{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1dVc4Jr_8At"
      },
      "source": [
        "# Prepara√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzZuZRLO_-vo"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmtRgtKB_1w8",
        "outputId": "4d95c66c-fad9-4145-dea2-607d6cd3ca77"
      },
      "outputs": [],
      "source": [
        "# Extra√ß√£o\n",
        "!pip -q install --upgrade py7zr wget\n",
        "\n",
        "# Google CLoud: BigQuery e GCS\n",
        "!pip install --upgrade -q google-cloud-bigquery google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05RsF1g_AHuP"
      },
      "outputs": [],
      "source": [
        "# Google Colab e servi√ßos de Cloud\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "# Bibliotecas padr√£o\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import wget\n",
        "import io\n",
        "from io import StringIO\n",
        "import os\n",
        "from os import remove\n",
        "from py7zr import SevenZipFile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhBXg5MAQQP"
      },
      "source": [
        "## Configurando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq--YRX7APz_"
      },
      "outputs": [],
      "source": [
        "# Autenticar\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mKtSSj8AVFe"
      },
      "outputs": [],
      "source": [
        "# Inicializa o cliente do GCS\n",
        "project_id = \"\"\n",
        "bucket_name = ''\n",
        "path_raw = ''\n",
        "\n",
        "gcs_client = storage.Client(project=project_id)\n",
        "bucket = gcs_client.get_bucket(bucket_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xknbViYQAcsO"
      },
      "source": [
        "# Extra√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPG79BhNA6_z"
      },
      "source": [
        "## Fun√ß√µes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ARKwOYBWGyo"
      },
      "outputs": [],
      "source": [
        "def salvar_no_gcs(arquivo_ou_df, path_blob):\n",
        "    try:\n",
        "        # Se for um DataFrame, salva como CSV tempor√°rio\n",
        "        if isinstance(arquivo_ou_df, DataFrame):\n",
        "            temp_file = \"temp.csv\"\n",
        "            arquivo_ou_df.to_csv(temp_file, index=False)\n",
        "        elif isinstance(arquivo_ou_df, str) and os.path.exists(arquivo_ou_df):\n",
        "            temp_file = arquivo_ou_df\n",
        "        else:\n",
        "            raise ValueError(\"Entrada deve ser um DataFrame ou caminho de arquivo existente.\")\n",
        "\n",
        "        # Envia para o GCS\n",
        "        blob = bucket.blob(path_blob)\n",
        "        blob.upload_from_filename(temp_file)\n",
        "        print(f\"üìÅ Salvo em: gs://{bucket_name}/{path_blob}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Erro ao salvar no GCS:\", e)\n",
        "\n",
        "    finally:\n",
        "        # Remove apenas o tempor√°rio criado internamente\n",
        "        if 'temp_file' in locals() and temp_file == \"temp.csv\" and os.path.exists(temp_file):\n",
        "            os.remove(temp_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONqXujwnHJSQ"
      },
      "outputs": [],
      "source": [
        "def extrair_e_carregar_dados_brutos(ano, mes):\n",
        "    \"\"\"\n",
        "    Realiza o download, extra√ß√£o e carga dos dados brutos do Novo CAGED para o GCS.\n",
        "    O per√≠odo do NOVO CAGED tem in√≠cio em Janeiro de 2020.\n",
        "    Essa fun√ß√£o n√£o extrai os microdados anteriores a esse per√≠odo devido a diverg√™ncias metodol√≥gicas estabelecidas pelo MTE.\n",
        "\n",
        "    S√£o 3 tipos de arquivo: CAGEDMOV, CAGEDFOR e CAGEDEXC.\n",
        "    1. CAGEDMOV: movimenta√ß√µes declaradas dentro do prazo com compet√™ncia de declara√ß√£o igual a AAAAMM.\n",
        "    2. CAGEDFOR: movimenta√ß√µes declaradas fora do prazo com compet√™ncia de declara√ß√£o igual a AAAAMM.\n",
        "    3. CAGEDEXC: movimenta√ß√µes exclu√≠das com compet√™ncia de declara√ß√£o da exclus√£o igual a AAAAMM.\n",
        "\n",
        "    Esta fun√ß√£o executa o processo em mem√≥ria:\n",
        "    1. Baixa o arquivo .7z do FTP do MTE.\n",
        "    2. Extrai o conte√∫do do arquivo .txt em mem√≥ria.\n",
        "    3. Envia o arquivo .txt diretamente para a camada 'bruto' do GCS.\n",
        "\n",
        "    Argumentos:\n",
        "        ano (int): Ano do arquivo.\n",
        "        mes (int): M√™s do arquivo.\n",
        "    \"\"\"\n",
        "    if ano < 2020:\n",
        "        print(f\"‚ùå Dados de {mes}/{ano} n√£o pertencem ao Novo CAGED. Ignorando.\")\n",
        "        return\n",
        "\n",
        "    tipos_arquivos = ['CAGEDEXC', 'CAGEDFOR', 'CAGEDMOV']\n",
        "    mes_str = str(mes).zfill(2)\n",
        "    pasta_temp = f\"tmp_caged_{ano}{mes_str}\"\n",
        "    os.makedirs(pasta_temp, exist_ok=True)\n",
        "\n",
        "    for tipo in tipos_arquivos:\n",
        "        nome_base_arquivo = f'{tipo}{ano}{mes_str}'\n",
        "        url = f'ftp://ftp.mtps.gov.br/pdet/microdados/NOVO CAGED/{ano}/{ano}{mes_str}/{nome_base_arquivo}.7z'\n",
        "        caminho_arquivo = os.path.join(pasta_temp, f\"{nome_base_arquivo}.7z\")\n",
        "        caminho_extraido = os.path.join(pasta_temp, f\"{nome_base_arquivo}.txt\")\n",
        "\n",
        "        print(f\"--- Processando {nome_base_arquivo} ---\")\n",
        "\n",
        "        # Download do arquivo .7z em mem√≥ria\n",
        "        try:\n",
        "            print(f'‚¨áÔ∏è Baixando {tipo} de {mes_str}/{ano}...')\n",
        "            wget.download(url, caminho_arquivo)\n",
        "        except Exception as e:\n",
        "            print(f'‚ùå Arquivo {nome_base_arquivo} indispon√≠vel: {e}')\n",
        "            continue\n",
        "\n",
        "        # Extra√ß√£o em mem√≥ria\n",
        "        try:\n",
        "            with SevenZipFile(caminho_arquivo, mode='r') as archive:\n",
        "              archive.extractall(path=pasta_temp)\n",
        "              print(f'‚úÖ Extra√≠do: {nome_base_arquivo}.txt')\n",
        "        except Exception as e:\n",
        "            print(f'‚ùå Erro na extra√ß√£o: {nome_base_arquivo} ‚Üí {e}')\n",
        "            continue\n",
        "\n",
        "        # Upload do conte√∫do extra√≠do para o GCS\n",
        "        try:\n",
        "            nome_extraido = f'{tipo}{ano}{mes_str}.txt'\n",
        "            path_gcs = f\"{path_raw}/ano={ano}/mes={mes_str}/{nome_extraido}\"\n",
        "            salvar_no_gcs(caminho_extraido, path_gcs)\n",
        "        except Exception as e:\n",
        "            print(f'‚ùå Erro ao enviar para GCS: {e}')\n",
        "            continue\n",
        "\n",
        "    # Remo√ß√£o do arquivo .7z e .txt ap√≥s upload\n",
        "    try:\n",
        "        shutil.rmtree(pasta_temp)\n",
        "        print(f\"üóëÔ∏è Pasta tempor√°ria removida: {pasta_temp}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao remover pasta tempor√°ria: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4M2jcr0FcPm"
      },
      "source": [
        "## Extra√ß√£o Completa (2020 - Hoje)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPDH2lnsFiS1",
        "outputId": "5c33cff6-93e5-4096-d336-3d730a7a5926"
      },
      "outputs": [],
      "source": [
        "# Extraindo arquivos para todo o per√≠odo\n",
        "for ano in range(2020, 2026):\n",
        "    for mes in range(1, 13):\n",
        "        extrair_e_carregar_dados_brutos(ano, mes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i29_DmMAFjY2"
      },
      "source": [
        "## Extra√ß√£o Espec√≠fica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHKY3Es_FlV2"
      },
      "outputs": [],
      "source": [
        "# Extraindo arquivos de um m√™s espec√≠fico\n",
        "extrair_e_carregar_dados_brutos(2025, 5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
